@inproceedings{10.1145/3447548.3467317,
author = {Wang, Qitong and Palpanas, Themis},
title = {Deep Learning Embeddings for Data Series Similarity Search},
year = {2021},
isbn = {9781450383325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3447548.3467317},
doi = {10.1145/3447548.3467317},
abstract = {A key operation for the (increasingly large) data series collection analysis is similarity
search. According to recent studies, SAX-based indexes offer state-of-the-art performance
for similarity search tasks. However, their performance lags under high-frequency,
weakly correlated, excessively noisy, or other dataset-specific properties. In this
work, we propose Deep Embedding Approximation (DEA), a novel family of data series
summarization techniques based on deep neural networks. Moreover, we describe SEAnet,
a novel architecture especially designed for learning DEA, that introduces the Sum
of Squares preservation property into the deep network design. Finally, we propose
a new sampling strategy, SEASam, that allows SEAnet to effectively train on massive
datasets. Comprehensive experiments on 7 diverse synthetic and real datasets verify
the advantages of DEA learned using SEAnet, when compared to other state-of-the-art
traditional and DEA solutions, in providing high-quality data series summarizations
and similarity search results.},
booktitle = {Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining},
pages = {1708â€“1716},
numpages = {9},
keywords = {indexing, neural networks, similarity search, sampling, data series},
location = {Virtual Event, Singapore},
series = {KDD '21}
}